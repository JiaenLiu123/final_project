{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All steps of the receipts extraction pipeline\n",
    "written by: Jiaen LIU \n",
    "\n",
    "This notebook will walk through all the steps of the pipeline to extarct the date from the receipts\n",
    "and automatically select the best hyper-parameters for the preprocessing by getting the best accuracy\n",
    "of the date extraction.  \n",
    "The following steps are included:  \n",
    "INPUT FOLDER  \n",
    "STEP 1. MobileNetV3-Large  \n",
    "STEP 2. Preprocess  \n",
    "STEP 3. OCR  \n",
    "STEP 4. Regex + Compare to ground truth  \n",
    "1. is it part of the candidate?  \n",
    "2. is the best candidate the ground truth?  \n",
    "3. if we take n best candidates, which n is the best? plot the accuracy vs n  \n",
    "STEP 5. Aggregate results use streamlit to visualize the results (thumnails of input and preprocessed, OCR results, regex results, final results(whether the ground in the candidates), accuracy vs n)\n",
    "OUTPUT FOLDER  \n",
    "STEP 6. Hyper-parameters selection  \n",
    "Let's start by importing the necessary libraries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import io\n",
    "import cv2\n",
    "import base64\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import re\n",
    "from dateutil import parser\n",
    "\n",
    "import pytesseract\n",
    "from skimage.filters import threshold_local\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as torchvision_T\n",
    "from torchvision.models.segmentation import deeplabv3_mobilenet_v3_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path=None,num_classes=2, model_name=\"mbv3\", device=torch.device(\"cpu\")):\n",
    "    \"\"\"Load the model from the given path.\n",
    "    Args:\n",
    "        model_path (str): Path to the model.\n",
    "        num_classes (int): Number of classes.\n",
    "        model_name (str): Name of the model.\n",
    "        device (torch.device): Device to load the model.\n",
    "    Returns:\n",
    "        model (torch.nn.Module): Loaded model.\n",
    "    \"\"\"\n",
    "    if model_name == \"mbv3\":\n",
    "        model = deeplabv3_mobilenet_v3_large(num_classes=num_classes, aux_loss=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} not supported.\")\n",
    "    if model_path is not None:\n",
    "        model.to(device)\n",
    "        checkpoints = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoints, strict=False)\n",
    "        model.eval()\n",
    "        _ = model(torch.rand(1, 3, 384, 384))\n",
    "    else:\n",
    "        raise ValueError(\"Model path not provided.\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test load_model\n",
    "model = load_model(model_path=\"model_mbv3_iou_mix_2C_aux_e3_pretrain.pth\", num_classes=2, model_name=\"mbv3\", device=torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess_transforms(mean=(0.4611, 0.4359, 0.3905), std=(0.2193, 0.2150, 0.2109)):\n",
    "    # Preprocessing transforms. Convert to tensor and normalize.\n",
    "    common_transforms = torchvision_T.Compose(\n",
    "        [\n",
    "            torchvision_T.ToTensor(),\n",
    "            torchvision_T.Normalize(mean, std),\n",
    "        ]\n",
    "    )\n",
    "    return common_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    \"\"\"Resize the image to the given width and height.\n",
    "    Args:\n",
    "        image (np.ndarray): Image to resize.\n",
    "        width (int): Width to resize to.\n",
    "        height (int): Height to resize to.\n",
    "        inter (int): Interpolation method.\n",
    "    Returns:\n",
    "        image (np.ndarray): Resized image.\n",
    "    \"\"\"\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "\n",
    "    # return the resized image\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a scanner effect to the image.\n",
    "def add_scanner_effect(img, parameters={\n",
    "    \"blur\": (5,5),\n",
    "    \"blur_iterations\": 1,\n",
    "    \"erode_kernel\": np.ones((3,3), np.uint8),\n",
    "    \"erode_iterations\": 1,\n",
    "    \"dilate_kernel\": np.ones((3,3), np.uint8),\n",
    "    \"dilate_iterations\": 1,\n",
    "    \"erode_kernel_2\": np.ones((3,3), np.uint8),\n",
    "    \"erode_iterations_2\": 1,\n",
    "    \"dilate_kernel_2\": np.ones((3,3), np.uint8),\n",
    "    \"dilate_iterations_2\": 1,\n",
    "    \"threshold_local_block_size\": 31,\n",
    "    \"threshold_local_offset\": 7,\n",
    "    # \"threshold_local_mode\": 'reflect',\n",
    "    \"sharpen_kernel\": np.array([[0,-1,0], [-1,7,-1], [0,-1,0]]),\n",
    "}):\n",
    "    # Convert the image to grayscale.\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply a Gaussian blur to the image.\n",
    "    img = cv2.GaussianBlur(img, parameters[\"blur\"], parameters[\"blur_iterations\"])\n",
    "\n",
    "    img = cv2.erode(img, parameters[\"erode_kernel\"], iterations=parameters[\"erode_iterations\"])\n",
    "    img = cv2.dilate(img, parameters[\"dilate_kernel\"], iterations=parameters[\"dilate_iterations\"])\n",
    "\n",
    "    # Apply a threshold to the image.\n",
    "    T = threshold_local(img, parameters[\"threshold_local_block_size\"], offset=parameters[\"threshold_local_offset\"], method=\"gaussian\")\n",
    "    img = (img > T).astype(\"uint8\") * 255\n",
    "    \n",
    "    # img = cv2.erode(img, parameters[\"erode_kernel_2\"], iterations=parameters[\"erode_iterations_2\"])\n",
    "    # img = cv2.dilate(img, parameters[\"dilate_kernel_2\"], iterations=parameters[\"dilate_iterations_2\"])\n",
    "\n",
    "    # Sharpen\n",
    "    img = cv2.filter2D(src=img, ddepth=-1, kernel=parameters[\"sharpen_kernel\"])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess_transforms(mean=(0.4611, 0.4359, 0.3905), std=(0.2193, 0.2150, 0.2109)):\n",
    "    # Preprocessing transforms. Convert to tensor and normalize.\n",
    "    common_transforms = torchvision_T.Compose(\n",
    "        [\n",
    "            torchvision_T.ToTensor(),\n",
    "            torchvision_T.Normalize(mean, std),\n",
    "        ]\n",
    "    )\n",
    "    return common_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    \"\"\"Rearrange coordinates to order:\n",
    "    top-left, top-right, bottom-right, bottom-left\"\"\"\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    pts = np.array(pts)\n",
    "    s = pts.sum(axis=1)\n",
    "    # Top-left point will have the smallest sum.\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    # Bottom-right point will have the largest sum.\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    # Top-right point will have the smallest difference.\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    # Bottom-left will have the largest difference.\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return rect.astype(\"int\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dest(pts):\n",
    "    (tl, tr, br, bl) = pts\n",
    "    # Finding the maximum width.\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # Finding the maximum height.\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    # Final destination co-ordinates.\n",
    "    destination_corners = [[0, 0], [maxWidth, 0], [maxWidth, maxHeight], [0, maxHeight]]\n",
    "\n",
    "    return order_points(destination_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(image_true=None, trained_model=None, image_size=384, BUFFER=10):\n",
    "    \"\"\"Scan the image and return the scanned image\n",
    "    Args:\n",
    "        image_true (np.array): Image to be scanned\n",
    "        trained_model (torch.nn.Module): Trained model\n",
    "        image_size (int): Size of the image to be fed to the model\n",
    "        BUFFER (int): Buffer to be added to the image\n",
    "    Returns:\n",
    "        scanned_image (np.array): Scanned image\n",
    "    \"\"\"\n",
    "    global preprocess_transforms\n",
    "\n",
    "    IMAGE_SIZE = image_size\n",
    "    half = IMAGE_SIZE // 2\n",
    "\n",
    "    imH, imW, C = image_true.shape\n",
    "\n",
    "    # Resizing the image to the size of input to the model. (384, 384)\n",
    "    image_model = cv2.resize(image_true, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    scale_x = imW / IMAGE_SIZE\n",
    "    scale_y = imH / IMAGE_SIZE\n",
    "\n",
    "    # Converting the image to tensor and normalizing it.\n",
    "    image_model = preprocess_transforms(image_model)\n",
    "    image_model = torch.unsqueeze(image_model, dim=0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Out: the output of the model\n",
    "        out = trained_model(image_model)[\"out\"].cpu()\n",
    "\n",
    "    del image_model\n",
    "    gc.collect()\n",
    "\n",
    "    out = torch.argmax(out, dim=1, keepdims=True).permute(0, 2, 3, 1)[0].numpy().squeeze().astype(np.int32)\n",
    "    r_H, r_W = out.shape\n",
    "\n",
    "    _out_extended = np.zeros((IMAGE_SIZE + r_H, IMAGE_SIZE + r_W), dtype=out.dtype)\n",
    "    _out_extended[half : half + IMAGE_SIZE, half : half + IMAGE_SIZE] = out * 255\n",
    "    out = _out_extended.copy()\n",
    "\n",
    "    del _out_extended\n",
    "    # Garbage collection\n",
    "    gc.collect()\n",
    "\n",
    "    # Edge Detection.\n",
    "    canny = cv2.Canny(out.astype(np.uint8), 225, 255)\n",
    "    canny = cv2.dilate(canny, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)))\n",
    "    contours, _ = cv2.findContours(canny, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    # Finding the largest contour. (Assuming that the largest contour is the document)\n",
    "    page = sorted(contours, key=cv2.contourArea, reverse=True)[0]\n",
    "\n",
    "    # ==========================================\n",
    "    epsilon = 0.02 * cv2.arcLength(page, True)\n",
    "    corners = cv2.approxPolyDP(page, epsilon, True)\n",
    "\n",
    "    corners = np.concatenate(corners).astype(np.float32)\n",
    "\n",
    "    corners[:, 0] -= half\n",
    "    corners[:, 1] -= half\n",
    "\n",
    "    corners[:, 0] *= scale_x\n",
    "    corners[:, 1] *= scale_y\n",
    "\n",
    "    # check if corners are inside.\n",
    "    # if not find smallest enclosing box, expand_image then extract document\n",
    "    # else extract document\n",
    "\n",
    "    if not (np.all(corners.min(axis=0) >= (0, 0)) and np.all(corners.max(axis=0) <= (imW, imH))):\n",
    "\n",
    "        left_pad, top_pad, right_pad, bottom_pad = 0, 0, 0, 0\n",
    "\n",
    "        rect = cv2.minAreaRect(corners.reshape((-1, 1, 2)))\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box_corners = np.int32(box)\n",
    "        #     box_corners = minimum_bounding_rectangle(corners)\n",
    "\n",
    "        box_x_min = np.min(box_corners[:, 0])\n",
    "        box_x_max = np.max(box_corners[:, 0])\n",
    "        box_y_min = np.min(box_corners[:, 1])\n",
    "        box_y_max = np.max(box_corners[:, 1])\n",
    "\n",
    "        # Find corner point which doesn't satify the image constraint\n",
    "        # and record the amount of shift required to make the box\n",
    "        # corner satisfy the constraint\n",
    "        if box_x_min <= 0:\n",
    "            left_pad = abs(box_x_min) + BUFFER\n",
    "\n",
    "        if box_x_max >= imW:\n",
    "            right_pad = (box_x_max - imW) + BUFFER\n",
    "\n",
    "        if box_y_min <= 0:\n",
    "            top_pad = abs(box_y_min) + BUFFER\n",
    "\n",
    "        if box_y_max >= imH:\n",
    "            bottom_pad = (box_y_max - imH) + BUFFER\n",
    "\n",
    "        # new image with additional zeros pixels\n",
    "        image_extended = np.zeros((top_pad + bottom_pad + imH, left_pad + right_pad + imW, C), dtype=image_true.dtype)\n",
    "\n",
    "        # adjust original image within the new 'image_extended'\n",
    "        image_extended[top_pad : top_pad + imH, left_pad : left_pad + imW, :] = image_true\n",
    "        image_extended = image_extended.astype(np.float32)\n",
    "\n",
    "        # shifting 'box_corners' the required amount\n",
    "        box_corners[:, 0] += left_pad\n",
    "        box_corners[:, 1] += top_pad\n",
    "\n",
    "        corners = box_corners\n",
    "        image_true = image_extended\n",
    "\n",
    "    corners = sorted(corners.tolist())\n",
    "    corners = order_points(corners)\n",
    "    destination_corners = find_dest(corners)\n",
    "    M = cv2.getPerspectiveTransform(np.float32(corners), np.float32(destination_corners))\n",
    "\n",
    "    final = cv2.warpPerspective(image_true, M, (destination_corners[2][0], destination_corners[2][1]), flags=cv2.INTER_LANCZOS4)\n",
    "    final = np.clip(final, a_min=0, a_max=255)\n",
    "    final = final.astype(np.uint8)\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the document from the image\n",
    "def extract_document(image, model_path, image_size=384):\n",
    "    \"\"\" Extract the document from the image\n",
    "    Args:\n",
    "        image (np.array): Image to be scanned\n",
    "    Returns:\n",
    "        scanned_image (np.array): Scanned image\n",
    "    \"\"\"\n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    final = scan(image_true=image, trained_model=model, image_size=image_size)\n",
    "    return final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR the document by using the pytesseract library.\n",
    "def ocr_document(image, lang=\"fra\", width=600):\n",
    "    \"\"\"\n",
    "    OCR the document by using the pytesseract library.\n",
    "    Args:\n",
    "        image (np.array): Image to be OCR'd\n",
    "        lang (str): Language of the document\n",
    "        width (int): Width of the image\n",
    "    Returns:\n",
    "        text (str): Text extracted from the document\n",
    "        image (np.array): Image with the scanner effect applied\n",
    "    \"\"\"\n",
    "   \n",
    "    imW = image.shape[1] # Get the size of the image\n",
    "    if imW > width:\n",
    "        # Resize the image to the width of 600 if the width is greater than 600 do that.\n",
    "        image = image_resize(image, width=width)\n",
    "    # Add a scanner effect to the image\n",
    "    image = add_scanner_effect(image)\n",
    "\n",
    "    return pytesseract.image_to_string(image, lang=lang),image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the regex to get the date from the text.\n",
    "# TODO: find a way to get the true date from current candidates.\n",
    "def get_date(text):\n",
    "    \"\"\"\n",
    "    Using the regex to get the date from the text.\n",
    "    Args:\n",
    "        text (str): Text to be searched\n",
    "    Returns:\n",
    "        date (str): Date found in the text\n",
    "    \"\"\"\n",
    "    # Lower the text\n",
    "    text = text.lower()\n",
    "    # Remove all the new line characters\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    # print(text)\n",
    "    # Get the date from the text\n",
    "    date = [x.group() for x in re.finditer( r'((?P<day>\\d{1,2}))(\\D{0,5})((?:(?:jan(?:v(?:ier)?)?)\\.?)|(?:(?:fév(?:r(?:ier)?)?)\\.?)|(?:(?:mar(?:s)?)\\.?)|(?:(?:avr(?:i(?:l)?)?)\\.?)|(?:mai\\.?)|(?:(?:jui(?:n)?)\\.?)|(?:(?:jui(?:l(?:let)?)?)\\.?)|(?:(?:aoû(?:t)?)\\.?)|(?:(?:sep(?:t(?:embre)?)?)\\.?)|(?:(?:oct(?:o(?:bre)?)?)\\.?)|(?:(?:nov(?:e(?:mbre)?)?)\\.?)|(?:(?:déc(?:e(?:mbre)?)?)\\.?)|(?P<month>\\d{1,2}))(\\D{0,5})((?P<year>\\d{2,4}))', text)]\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['75013',\n",
       " '01 45 70',\n",
       " '80 00',\n",
       " '306 243',\n",
       " '833 0004',\n",
       " '8S 306',\n",
       " '243 833',\n",
       " '05/11/2022',\n",
       " '17:32:05',\n",
       " '0.544',\n",
       " '21.90 3364',\n",
       " '69206110',\n",
       " '11.91',\n",
       " '11.91',\n",
       " '0.544',\n",
       " '50% 0.62',\n",
       " '15.00',\n",
       " '1.0.104',\n",
       " '00 - 20h00',\n",
       " '8h00 - 20',\n",
       " '8h00 - 13']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.group() for x in re.finditer( r'((?P<day>\\d{1,2}))(\\D{0,5})((?:(?:jan(?:v(?:ier)?)?)\\.?)|(?:(?:fév(?:r(?:ier)?)?)\\.?)|(?:(?:mar(?:s)?)\\.?)|(?:(?:avr(?:i(?:l)?)?)\\.?)|(?:mai\\.?)|(?:(?:jui(?:n)?)\\.?)|(?:(?:jui(?:l(?:let)?)?)\\.?)|(?:(?:aoû(?:t)?)\\.?)|(?:(?:sep(?:t(?:embre)?)?)\\.?)|(?:(?:oct(?:o(?:bre)?)?)\\.?)|(?:(?:nov(?:e(?:mbre)?)?)\\.?)|(?:(?:déc(?:e(?:mbre)?)?)\\.?)|(?P<month>\\d{1,2}))(\\D{0,5})((?P<year>\\d{2,4}))', '''— TANG FRERES GOURMET 48 AVENUE D'IVRY 75013 PARIS Tel : 01 45 70 80 00 siret : 306 243 833 00044 TVA INTRA : FR8S 306 243 833 *$‘t>t*#'**ﬂ**********ñ***1A‘A4w***—k********** | samedi 05/11/2022 17:32:05 Ticket 371 Caisse No 6 ; Caissiere Ha ; dan Magasin G03 CODE LIBELLE PRIX NET EURO QUANTITE 0.544 x 21.90 336469206110 ECHINE DE PORC LAQUE 11.91 — ia Total TTC Euros 11.91 Nombre d'articles : 0.544 Détail Tva : _TVA à 5.50% 0.62 Reglement(s) $ Paiement Espèces EURO 15.00 À Rendu Espèces EURg - 3.09 NeoLog - Logicie] NeoPos Version 1.0.104 Signature numérique : B-NEOP-EyxA **************************************%*** Horaires du Magasin : Fermé le Lundi Mardi au Vendredi : Sh00 - 20h00 Samedi : 8h00 - 20h00 Dimanche : 8h00 - 13h00 **************************\"\"*****’Ï‘***Î‘***** Merci de Votre Visite et à Bientôt \\ ('3\\‘,—' F ù''')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some hyperparameters\n",
    "IMAGE_SIZE = 384\n",
    "preprocess_transforms = image_preprocess_transforms()\n",
    "image = None\n",
    "final = None\n",
    "result = None\n",
    "INPUT_FOLDER = \"input\"\n",
    "OUTPUT_FOLDER = \"output\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all pictures in the folder\n",
    "receipt_files = glob(INPUT_FOLDER + \"/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'à s\\n* (3\\n«& city\\n. Ld\\nCRF—CITY LA ROCHELLE\\n33 RUE DE LÀ SCIERIE\\n\\n17000 LÀ ROŒCHELLE\\nTel : 05.46.27.02.12\\n\\nDESCR/PTISK [03 KOWTÉ\\n\\n+1509 {DV TR.PAL PL 2.3\\n=;804 CKIPS CNDULEE 1.4\\n+1908 {DW TR. JBX C 3.7\\n\\n3 fL.IICLECS) TOTAL A PAYER 6.99\\nCB EMV SANS CONTACT EUR 6.99€\\n\\n01 05 093 000009— 25/02/2017 .— rp:Cs:s\\n\\n(S MERCI DE VOTRE VYISITE\\nÀ BIENTOT\\n\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_date(result)\n",
    "test.append(\"1701-12\")\n",
    "# test.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k5/j33smc310f1038b26bybvjvm0000gn/T/ipykernel_38011/1606942962.py:2: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  out = pd.to_datetime(test, errors='coerce').dropna().strftime('%d-%b-%Y %H:%M').tolist()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['01-May-1993 00:00', '25-Feb-2017 00:00', '01-Dec-1701 00:00']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "out = pd.to_datetime(test, errors='coerce').dropna().strftime('%d-%b-%Y %H:%M').tolist()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'25/02/2017'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step1: if the ground truth is in the candidate list, then we say it is good\n",
    "# step2: is the best candidate is in the ground truth, then we say it is good\n",
    "# step3: if the ground truth is in the best candidates, then we say it is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-02-25 00:00:00\n",
      "2017-02-25 00:00:00\n",
      "2022-11-02 00:00:00\n",
      "1509-11-30 00:00:00\n",
      "1509-11-30 00:00:00\n",
      "1509-11-30 00:00:00\n",
      "1509-11-30 00:00:00\n",
      "1993-05-30 00:00:00\n",
      "1993-05-30 00:00:00\n",
      "2017-02-25 00:00:00\n",
      "1701-12-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "for time in test:\n",
    "    try:\n",
    "        date = parser.parse(time)\n",
    "    except:\n",
    "        pass\n",
    "    print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LESCAIPTICA dt voutet\n",
      "3208 SLB.WÏTM [AL\n",
      "PORNE aoLDEA 990\n",
      "g 36004 X _1.50(M\n",
      "\n",
      "comssnamnett* ____,.—,—-,;;.—-—______.—_...;—_—.::—‘--—-- st\n",
      "2 ONTIELECS) TOTAL ® POYER 5 04t\n",
      "-:_...-———--—-,:—\"‘.,..___..-—__:—;: —-_:“.—-—-.:‘_:”-*“'::—-*“‘….———*“'\n",
      "CARTE BANCAIRE ç  ER 5.04\n",
      "j9:79:0\n",
      "\n",
      "[('3', '3', '', '2', '2', '', '08', '08'), ('99', '99', '', '0', '0', '\\ng ', '3600', '3600'), ('4', '4', ' X _', '1', '1', '.', '50', '50'), ('04', '04', '\\nj', '9', '9', ':', '79', '79')]\n",
      "Carref\n",
      "ae<gg;(®\n",
      "\n",
      "CRF—CITY LA ROCHELLE\n",
      "33 RUE DE LA SCIERIE\n",
      "17000 _ LA E\n",
      "Tel : 05.46.27.02.12\n",
      "\n",
      "TESCRIPTIOIL L NOTRAT\n",
      "2008 SCHKOSONS K1 3126\n",
      "75 CAD Gt RSE KOD 4156\n",
      "PREFOU CHEURE 4806\n",
      "r_:—=:::æ:‘;:ﬂlﬁx:æ:£ï—\".:z::ﬁ::\n",
      "\n",
      "3 MIILEGS) TOTAL A PATER 1206\n",
      "\n",
      "CARTE BANCATRE EMY — RR 12.07€\n",
      "9012 . 004/ c00119 —— M/N0/06 19:15:57\n",
      "\n",
      "MERCT DE VOTRE VISITE\n",
      "A BIENTOT\n",
      "\n",
      "[('17', '17', '', '0', '0', '', '00', '00'), ('05', '05', '.', '46', '46', '.', '27', '27'), ('0', '0', '', '2', '2', '.', '12', '12'), ('2', '2', '', '0', '0', '', '08', '08'), ('1', '1', ' ', '31', '31', '', '26', '26'), ('4', '4', '', '1', '1', '', '56', '56'), ('4', '4', '', '8', '8', '', '06', '06'), ('1', '1', '', '2', '2', '', '06', '06'), ('12', '12', '.', '07', '07', '€\\n', '9012', '9012'), ('00', '00', '', '4', '4', '/ c', '0011', '0011'), ('0', '0', '/', '06', '06', ' ', '19', '19'), ('1', '1', '', '5', '5', ':', '57', '57')]\n",
      "à Carrefgg; {(©\n",
      "\n",
      "CRF—CITY LA ROCHELLE\n",
      "33 RUE OE LA SCIERIE\n",
      "17000 LÀ ROCHELLE\n",
      "Tel : 05.46.27.02.12\n",
      "\n",
      "DESCRIPT IOA 0IE NCATANT\n",
      "\n",
      "SALADE PATE JS0N . 3. 626\n",
      "— TRN8E® — TmARt dae\n",
      "CARTE BANCATRE EMV .— eUR 3.82€\n",
      "\n",
      "0908— 004— 000162— 28/01/016 . 12:58:10\n",
      "\n",
      "MERCI DE VOTRE YISITE\n",
      "À BIENTOT\n",
      "\n",
      "\n",
      "[('17', '17', '', '0', '0', '', '00', '00'), ('05', '05', '.', '46', '46', '.', '27', '27'), ('0', '0', '', '2', '2', '.', '12', '12'), ('0', '0', 'N . ', '3', '3', '. ', '626', '626'), ('3', '3', '.', '82', '82', '€\\n\\n', '0908', '0908'), ('00', '00', '', '4', '4', '— ', '0001', '0001'), ('62', '62', '— ', '28', '28', '/', '01', '01'), ('01', '01', '', '6', '6', ' . ', '12', '12'), ('5', '5', '', '8', '8', ':', '10', '10')]\n",
      "<& —a'îg;\n",
      "\n",
      "CRF—CITY LA ROCHELLE\n",
      "33 RUE DE LA SCIERIE\n",
      "17000 — LÀ ROCHELLE\n",
      "Tel : 05.46.27,02.12\n",
      "\n",
      "‘ PTIOX IE RONTA\n",
      "\n",
      "f SCROKOBONS 4.8\n",
      "\n",
      "LTICLECS) TOTAL À PAYER\n",
      "\n",
      "CES EUR _ ..... 5 10.00€\n",
      "Votre Mopnaie —.. . . — —. . ‘—5.13€\n",
      "\n",
      "t 06 003 000136 20/12/2016 — 19:39:08\n",
      "\n",
      "[('17', '17', '', '0', '0', '', '00', '00'), ('05', '05', '.', '46', '46', '.', '27', '27'), ('0', '0', '', '2', '2', '.', '12', '12'), ('5', '5', ' ', '10', '10', '.', '00', '00'), ('5', '5', '.', '13', '13', '€\\n\\nt ', '06', '06'), ('00', '00', '', '3', '3', ' ', '0001', '0001'), ('36', '36', ' ', '20', '20', '/', '12', '12'), ('20', '20', '', '16', '16', ' — ', '19', '19'), ('3', '3', '', '9', '9', ':', '08', '08')]\n",
      "\\\n",
      "Carrefour (äà\n",
      "\n",
      "CRF—CITY LA RŒHELLE\n",
      "33 RUE DE LA SCIERIE\n",
      "17000— LA ROCHELLE\n",
      "Tel : 05.45.27.02.12.\n",
      "\n",
      "iESCRPTIS lu KONTAAT\n",
      "4006 TRESOR DUO CH MMe\n",
      "6 CESF 6R0S ExTRA : — 0 1us\n",
      "BARKE 810 1.58€\n",
      "0.7182 x : + 2.20€\n",
      "BISCOT.HULTT CERÇA\n",
      "LT 1/2€ HATIM LEGE\n",
      "PLZZA TOKNO RISTOR\n",
      "\n",
      "CARTE BANCAIRE EMY  EUR > 14.46€\n",
      "\n",
      "S1 vous aviez la carte fidélité,\n",
      "vous auriez cueulé 0.06€ sur\n",
      "votre compte fidé]ité Carrefour.\n",
      "\n",
      "Détails:\n",
      "\n",
      "BISCOT.MULTI CEREA 0.05€\n",
      "\n",
      "0001 002 — 00081 2/0M/206 — 20:25:13\n",
      "\n",
      "MERCI DE VOTRE VISITE\n",
      "A BIENTOT\n",
      "\n",
      "\n",
      "[('17', '17', '', '0', '0', '', '00', '00'), ('05', '05', '.', '45', '45', '.', '27', '27'), ('0', '0', '', '2', '2', '.', '12', '12'), ('4', '4', '', '0', '0', '', '06', '06'), ('10', '10', ' ', '1', '1', '.', '58', '58'), ('0', '0', '.', '71', '71', '', '82', '82'), ('1', '1', '', '4', '4', '.', '46', '46'), ('0', '0', '.', '05', '05', '€\\n\\n', '0001', '0001'), ('00', '00', '', '2', '2', ' — ', '0008', '0008'), ('2', '2', '/', '0', '0', 'M/', '206', '206'), ('20', '20', ':', '25', '25', ':', '13', '13')]\n",
      "Carrefgfg; (Q—.}\n",
      "\n",
      "CRF—CITY LA ROCHELLE\n",
      "33 RUE DE LA SCIERIE\n",
      "17000 _ LA ROCHÊLLE\n",
      "Tel : 05.46.27.02.12\n",
      "\n",
      "DESCRIPTION [43 NONTAŸT\n",
      "D.PIZZA 4 FORHASSI 4,90t\n",
      "PIZZA ASAÏSCNS CRP 2. nt\n",
      "\n",
      "2 fâTICLECS) TOTAL @ PAYER 7.62€\n",
      "CARTE BARCAIRE EMY — ElR 7.62€\n",
      "\n",
      "0803 002 000282— 09/06/2016 20:00:19\n",
      "\n",
      "MERCI DE VOTRE VISITE\n",
      "À BIENTOT\n",
      "\n",
      "[('17', '17', '', '0', '0', '', '00', '00'), ('05', '05', '.', '46', '46', '.', '27', '27'), ('0', '0', '', '2', '2', '.', '12', '12'), ('7', '7', '.', '62', '62', '€\\n\\n', '0803', '0803'), ('00', '00', '', '2', '2', ' ', '0002', '0002'), ('82', '82', '— ', '09', '09', '/', '06', '06'), ('20', '20', '', '16', '16', ' ', '20', '20'), ('0', '0', '', '0', '0', ':', '19', '19')]\n",
      "Carrefour\n",
      "refogr\n",
      "\n",
      "CRF—CITY LA ROCHELL\n",
      "33 RUE DE LA SCIERII\n",
      "17000 _ LÀ ROCHELLE\n",
      "Tel : 05.46.27.02.12\n",
      "\n",
      "CR—PTION\n",
      "\n",
      "EMV SANS CONTACT EUR\n",
      "\n",
      "O( 03 003 . 000120 24/08/201\n",
      "\n",
      "ErCI DE_VOTRE vIS\n",
      "MERC* / preNTOT\n",
      "\n",
      "[('17', '17', '', '0', '0', '', '00', '00'), ('05', '05', '.', '46', '46', '.', '27', '27'), ('0', '0', '', '2', '2', '.', '12', '12'), ('03', '03', ' ', '0', '0', '', '03', '03'), ('00', '00', '', '01', '01', '', '20', '20'), ('24', '24', '/', '08', '08', '/', '201', '201')]\n",
      "17000\n",
      "T61 : 05.46.27.02—12\n",
      "pESCAIPTICN : dtt jors\n",
      "958 VERRIKE TIRANI 2\n",
      "pARHENTIER CANARD 4.1\n",
      "---—-:::::.—:=r_;:::::::;æ:::::::—.:::—-r_..—-——-ä\n",
      "2 nnrrasm TOTAL A PâVER 6.1\n",
      "::::;::::::s::*--*--* ..:::::‘.:——:-<,—;ﬁ-;:—-\"\n",
      "p EMV SANS CONT 6.74\n",
      "s1 aÿw]ëa f1dés‘ljirté.\n",
      "urieZ :\n",
      "vavlâtî € fldéHté Çarrefou”.\n",
      "pétatist .s 30£\n",
      "—————————————— 0.\n",
      "gemise pr uitS fid |\n",
      "7 1124\n",
      "9006\n",
      "TRE vIS\n",
      "\n",
      "[('17', '17', '', '0', '0', '', '00', '00'), ('61', '61', ' : ', '05', '05', '.', '46', '46'), ('27', '27', '.', '02', '02', '—', '12', '12'), ('7', '7', ' ', '11', '11', '', '24', '24'), ('9', '9', '', '0', '0', '', '06', '06')]\n",
      "<ë%a aîy\n",
      "\n",
      "CRF—CITY LÀ ROCHELLE\n",
      "33 RUE DE LA SCIERIE\n",
      "17000— LA ROCHELLE\n",
      "Tel : 05.46.27.02.12\n",
      "\n",
      "DESCAIPTICI dIe wr\n",
      "+2058 DESSERT WOTR 2.1\n",
      "»3638 GAUFRE CHOLD 3.0\n",
      "+40%L AERÊTTE 3t 1.8\n",
      "+6 CEUF PLEDA ATR 6 1.3\n",
      "»KERISAC CIDRE BRUT 2.\n",
      "\n",
      "5 ARTICLECS) ——— TOTAL A PAYER 11.1\n",
      "CB EV SANS CONTACT —EUR 11.16\n",
      "\n",
      "Si vous aviez la carte fidélité,\n",
      "vous auriez cumulé 0.09€ sur\n",
      "votre compte fidélité Carrefour.\n",
      "\n",
      "Détails:\n",
      "\n",
      "5% produits Carrefou 0. 09\n",
      "\n",
      "Lida) où4 — 00105 — 26/00/07— 11\n",
      "\n",
      "MERCI DE YOTRE VISITE\n",
      "A BIENTOT\n",
      "\n",
      "[('17', '17', '', '0', '0', '', '00', '00'), ('05', '05', '.', '46', '46', '.', '27', '27'), ('0', '0', '', '2', '2', '.', '12', '12'), ('2', '2', '', '0', '0', '', '58', '58'), ('2', '2', '.', '1', '1', '\\n»', '3638', '3638'), ('3', '3', '.', '0', '0', '\\n+', '40', '40'), ('1', '1', '', '1', '1', '.', '16', '16'), ('4', '4', ' — ', '00', '00', '', '105', '105'), ('26', '26', '/', '00', '00', '/', '07', '07')]\n",
      "à s\n",
      "* (3\n",
      "«& city\n",
      ". Ld\n",
      "CRF—CITY LA ROCHELLE\n",
      "33 RUE DE LÀ SCIERIE\n",
      "\n",
      "17000 LÀ ROŒCHELLE\n",
      "Tel : 05.46.27.02.12\n",
      "\n",
      "DESCR/PTISK [03 KOWTÉ\n",
      "\n",
      "+1509 {DV TR.PAL PL 2.3\n",
      "=;804 CKIPS CNDULEE 1.4\n",
      "+1908 {DW TR. JBX C 3.7\n",
      "\n",
      "3 fL.IICLECS) TOTAL A PAYER 6.99\n",
      "CB EMV SANS CONTACT EUR 6.99€\n",
      "\n",
      "01 05 093 000009— 25/02/2017 .— rp:Cs:s\n",
      "\n",
      "(S MERCI DE VOTRE VYISITE\n",
      "À BIENTOT\n",
      "\n",
      "\n",
      "[('17', '17', '', '0', '0', '', '00', '00'), ('05', '05', '.', '46', '46', '.', '27', '27'), ('0', '0', '', '2', '2', '.', '12', '12'), ('1', '1', '', '5', '5', '', '09', '09'), ('2', '2', '.', '3', '3', '\\n=;', '804', '804'), ('1', '1', '.', '4', '4', '\\n+', '1908', '1908'), ('6', '6', '.', '99', '99', '€\\n\\n', '01', '01'), ('05', '05', ' ', '0', '0', '', '93', '93'), ('00', '00', '', '00', '00', '', '09', '09'), ('25', '25', '/', '02', '02', '/', '2017', '2017')]\n"
     ]
    }
   ],
   "source": [
    "# For each picture in the folder do the following steps\n",
    "for receipt_file in receipt_files:\n",
    "    # Read the image\n",
    "    image = cv2.imread(receipt_file)\n",
    "    # Extract the document\n",
    "    final = extract_document(image, \"model_mbv3_iou_mix_2C_aux_e3_pretrain.pth\", IMAGE_SIZE)\n",
    "    # OCR the document\n",
    "    result,scanned_image = ocr_document(final)\n",
    "    # Save the image\n",
    "\n",
    "    # create the output folder if it doesn't exist\n",
    "    if not os.path.exists(OUTPUT_FOLDER):\n",
    "        os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "    cv2.imwrite(OUTPUT_FOLDER + \"/\" + receipt_file.split(\"/\")[-1], scanned_image)\n",
    "    # Print the result\n",
    "    print(result)\n",
    "    # write the result in a text file\n",
    "    with open(OUTPUT_FOLDER + \"/\" + receipt_file.split(\"/\")[-1].split(\".\")[0] + \".txt\", \"w\") as f:\n",
    "        f.write(result)\n",
    "    \n",
    "    # Get the date from the text\n",
    "    date = get_date(result)\n",
    "    print(date)\n",
    "    # write the date in a text file\n",
    "    with open(OUTPUT_FOLDER + \"/\" + receipt_file.split(\"/\")[-1].split(\".\")[0] + \"_date.txt\", \"w\") as f:\n",
    "        f.write(str(date))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread(\"output.png\")\n",
    "\n",
    "# Create a grayscale version of the image\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Define a kernel for the scanner effect\n",
    "scanner_kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "\n",
    "# Apply the scanner effect to the grayscale image\n",
    "scanner = cv2.filter2D(gray, -1, scanner_kernel)\n",
    "\n",
    "# resize the image to scanner size\n",
    "# img = cv2.resize(img, (img.shape[1], img.shape[0]))\n",
    "\n",
    "\n",
    "# Combine the original image with the scanner effect\n",
    "result = cv2.addWeighted(gray, 0.5, scanner, 0.5, 0)\n",
    "\n",
    "# Save the resulting image\n",
    "cv2.imwrite(\"result.png\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('/Users/liujiaen/Documents/Text_Recognition/Document-Scanner-Custom-Semantic-Segmentation-using-PyTorch-DeepLabV3/test_images/IMG_3481.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply a Gaussian blur to the image to reduce noise\n",
    "\n",
    "blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Use Canny edge detection to find the edges in the image\n",
    "edges = cv2.Canny(blur, 50, 150)\n",
    "\n",
    "# Run the Hough transform on the edge-detected image to detect lines\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=100, maxLineGap=10)\n",
    "\n",
    "# create a white image with the same size as the original image\n",
    "mask = np.zeros_like(image)\n",
    "mask.fill(255)\n",
    "\n",
    "# Draw the lines on the white image\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(mask, (x1, y1), (x2, y2), (0, 0, 0), 2)\n",
    "\n",
    "cv2.imwrite('mask.png', mask)\n",
    "\n",
    "# Draw the lines on the original image\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "# Save the resulting image\n",
    "cv2.imwrite('receipt_edges.png', image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2599, 1731, 3), (2599, 1731), (2599, 1731))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape, scanner.shape, result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(469, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/Users/liujiaen/Documents/Text_Recognition/dataset/findit/FindIt-Dataset-Train/T1-train/train.csv\")\n",
    "df.head()\n",
    "print(df.shape)\n",
    "len(df[df[\"correct\"] == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = df[df[\"correct\"] == True]\n",
    "correct.to_csv(\"correct.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([[422, 690], [1185, 690], [1185, 782], [422, 782]], 'CRF-CITY LA ROCHELLE', 0.7758780484401733), ([[421, 780], [1187, 780], [1187, 876], [421, 876]], '33 RUE DE LA SCIERIE', 0.6374939756836588), ([[427, 871], [627, 871], [627, 959], [427, 959]], '17000', 0.9733525592215241), ([[759, 873], [1185, 873], [1185, 965], [759, 965]], 'LA ROCHELLE', 0.9810264028810408), ([[424, 962], [550, 962], [550, 1050], [424, 1050]], 'Tel', 0.9839941354527475), ([[587, 990], [616, 990], [616, 1037], [587, 1037]], \"'\", 0.11441381604890921), ([[645, 962], [1185, 962], [1185, 1053], [645, 1053]], '05 , 46, 27 ,02, 12', 0.4825177609498993), ([[1277, 1032], [1564, 1032], [1564, 1141], [1277, 1141]], \"'\", 0.3146761157580933), ([[819, 1171], [1331, 1171], [1331, 1287], [819, 1287]], '', 0.0), ([[116, 1317], [447, 1317], [447, 1398], [116, 1398]], 'DESCRIPTIOA', 0.5370612612450623), ([[831, 1331], [1056, 1331], [1056, 1422], [831, 1422]], '.', 0.12504872222509622), ([[1092, 1323], [1195, 1323], [1195, 1396], [1092, 1396]], 'QTE', 0.8948694651728182), ([[1453, 1327], [1663, 1327], [1663, 1395], [1453, 1395]], 'HontAHT', 0.22940455919921468), ([[87, 1498], [641, 1498], [641, 1582], [87, 1582]], '*85G VERRINE TIRAKI', 0.7654675134875422), ([[1509, 1507], [1667, 1507], [1667, 1579], [1509, 1579]], '2.01€', 0.34877788034303386), ([[88, 1592], [609, 1592], [609, 1664], [88, 1664]], '*PARMENTIER CANARD', 0.43023753811605675), ([[1510, 1599], [1663, 1599], [1663, 1666], [1510, 1666]], '4.73e', 0.4037824945342389), ([[177, 1773], [524, 1773], [524, 1851], [177, 1851]], '2 ARTICLE()', 0.889046334029025), ([[677, 1778], [832, 1778], [832, 1850], [677, 1850]], 'TOTAL', 0.9909421784743606), ([[846, 1778], [1058, 1778], [1058, 1850], [846, 1850]], 'A PAYER', 0.5863676300338838), ([[1485, 1782], [1641, 1782], [1641, 1849], [1485, 1849]], '6.74', 0.9626611373693944), ([[90, 2049], [816, 2049], [816, 2140], [90, 2140]], 'CB  EMV SANS CONTACT', 0.6524633988000893), ([[873, 2052], [1005, 2052], [1005, 2140], [873, 2140]], 'EUR', 0.999676320620024), ([[1428, 2055], [1637, 2055], [1637, 2143], [1428, 2143]], '6,74e', 0.3561600944143354), ([[313, 2235], [404, 2235], [404, 2320], [313, 2320]], 'Si', 0.9975371530563701), ([[427, 2235], [819, 2235], [819, 2320], [427, 2320]], 'vous aviez', 0.6942864646923302), ([[842, 2232], [1500, 2232], [1500, 2323], [842, 2323]], 'Ia carte fidelite', 0.6372991856040267), ([[203, 2321], [898, 2321], [898, 2418], [203, 2418]], 'vous auriez cumule', 0.6267206109101121), ([[1059, 2324], [1414, 2324], [1414, 2415], [1059, 2415]], '0.30e sur', 0.6895426704329696), ([[274, 2409], [1462, 2409], [1462, 2529], [274, 2529]], 'votre compte fidelite Carrefour_', 0.9556341141616527), ([[164, 2601], [476, 2601], [476, 2689], [164, 2689]], 'Details;', 0.7276224573961458), ([[1557, 2730], [1579, 2730], [1579, 2743], [1557, 2743]], 'Rne', 0.009547074520667668), ([[274, 2773], [1044, 2773], [1044, 2881], [274, 2881]], 'Remise produits fide', 0.9932955887956003), ([[1354, 2781], [1562, 2781], [1562, 2870], [1354, 2870]], '0,30€', 0.5213461335973729), ([[232, 2963], [356, 2963], [356, 3031], [232, 3031]], '0006', 0.993298351764679), ([[484, 2963], [579, 2963], [579, 3031], [484, 3031]], '004', 0.9658574461936951), ([[706, 2959], [889, 2959], [889, 3032], [706, 3032]], '000122', 0.9691079296819883), ([[1012, 2959], [1310, 2959], [1310, 3034], [1012, 3034]], '27/02/2017', 0.9994834696331099), ([[1404, 2959], [1642, 2959], [1642, 3032], [1404, 3032]], '12:24.45', 0.6653415152697131), ([[612, 3232], [1418, 3232], [1418, 3328], [612, 3328]], 'HERCI   DE VOTRE VISITE', 0.7410814687317221), ([[846, 3343], [883, 3343], [883, 3398], [846, 3398]], 'A', 0.09266784959557928), ([[911, 3330], [1193, 3330], [1193, 3419], [911, 3419]], 'BIENTOT', 0.9913146646786485), ([[828.9500453018884, 189.01198422271392], [1488.2546848039835, 345.44918835692044], [1382.0499546981116, 718.9880157772861], [722.7453151960163, 562.5508116430796]], 'city)', 0.7471071448105876)]\n"
     ]
    }
   ],
   "source": [
    "# Test easy ocr\n",
    "\n",
    "from easyocr import Reader\n",
    "import cv2\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread(\"/home/jiaenliu/final_project/testimage/4.jpg\")\n",
    "\n",
    "# OCR the image\n",
    "reader = Reader(['en'], gpu=True)\n",
    "result = reader.readtext(image,)\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output.txt\", \"w\") as f:\n",
    "    for item in result:\n",
    "        text = str(item[1]).replace(\"\\n\", \"\")\n",
    "        f.write(text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([[[422, 1185, 690, 782], [421, 1187, 780, 876], [427, 627, 871, 959], [759, 1185, 873, 965], [424, 550, 962, 1050], [587, 616, 990, 1037], [645, 1185, 962, 1053], [1277, 1564, 1032, 1141], [819, 1331, 1171, 1287], [116, 447, 1317, 1398], [831, 1056, 1331, 1422], [1092, 1195, 1323, 1396], [1453, 1663, 1327, 1395], [87, 641, 1498, 1582], [1509, 1667, 1507, 1579], [88, 609, 1592, 1664], [1510, 1663, 1599, 1666], [177, 524, 1773, 1851], [677, 832, 1778, 1850], [846, 1058, 1778, 1850], [1485, 1641, 1782, 1849], [90, 816, 2049, 2140], [873, 1005, 2052, 2140], [1428, 1637, 2055, 2143], [313, 404, 2235, 2320], [427, 819, 2235, 2320], [842, 1500, 2232, 2323], [203, 898, 2321, 2418], [1059, 1414, 2324, 2415], [274, 1462, 2409, 2529], [164, 476, 2601, 2689], [1557, 1579, 2730, 2743], [274, 1044, 2773, 2881], [1354, 1562, 2781, 2870], [232, 356, 2963, 3031], [484, 579, 2963, 3031], [706, 889, 2959, 3032], [1012, 1310, 2959, 3034], [1404, 1642, 2959, 3032], [612, 1418, 3232, 3328], [846, 883, 3343, 3398], [911, 1193, 3330, 3419]]], [[[[828.9500453018884, 189.01198422271392], [1488.2546848039835, 345.44918835692044], [1382.0499546981116, 718.9880157772861], [722.7453151960163, 562.5508116430796]]]])\n"
     ]
    }
   ],
   "source": [
    "test = reader.detect(image)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[422, 1185, 690, 782], [421, 1187, 780, 876], [427, 627, 871, 959], [759, 1185, 873, 965], [424, 550, 962, 1050], [587, 616, 990, 1037], [645, 1185, 962, 1053], [1277, 1564, 1032, 1141], [819, 1331, 1171, 1287], [116, 447, 1317, 1398], [831, 1056, 1331, 1422], [1092, 1195, 1323, 1396], [1453, 1663, 1327, 1395], [87, 641, 1498, 1582], [1509, 1667, 1507, 1579], [88, 609, 1592, 1664], [1510, 1663, 1599, 1666], [177, 524, 1773, 1851], [677, 832, 1778, 1850], [846, 1058, 1778, 1850], [1485, 1641, 1782, 1849], [90, 816, 2049, 2140], [873, 1005, 2052, 2140], [1428, 1637, 2055, 2143], [313, 404, 2235, 2320], [427, 819, 2235, 2320], [842, 1500, 2232, 2323], [203, 898, 2321, 2418], [1059, 1414, 2324, 2415], [274, 1462, 2409, 2529], [164, 476, 2601, 2689], [1557, 1579, 2730, 2743], [274, 1044, 2773, 2881], [1354, 1562, 2781, 2870], [232, 356, 2963, 3031], [484, 579, 2963, 3031], [706, 889, 2959, 3032], [1012, 1310, 2959, 3034], [1404, 1642, 2959, 3032], [612, 1418, 3232, 3328], [846, 883, 3343, 3398], [911, 1193, 3330, 3419]]]\n"
     ]
    }
   ],
   "source": [
    "print(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "receipt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "903843664969acf17be6d270dae43f3dd8ec2da94c5c66ccffa6235e417105bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
